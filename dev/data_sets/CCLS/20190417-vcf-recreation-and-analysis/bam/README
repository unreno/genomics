

What to do with multiple ALT calls? Split call? Threshold? Drop?

Filter on Biases?

How to keep strand in VCF?





for sample in 983899 268325 439338 63185 634370 120207 122997 186069 201771 209605 266836 321666 341203 36077 492023 495910 506458 530196 607654 673944 73753 780690 811386 813891 833536 853767 866648 868614 871719 900420 919207 972727 99776 ; do
for chr in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X ; do
echo ./create_somatic_vcfs.bash $sample $chr \>\> ${sample}.${chr}.create_somatic_vcfs.log 2\>\&1
done ; done | parallel -j 40 --no-notice --joblog parallel.log &



Even after a number of mods, count_trinuc_muts_v8.pl still takes memory into swap
something in the perl script is eating lots of memory for no reason. probably the db fasta


for sample in 983899 268325 439338 63185 634370 120207 122997 186069 201771 209605 266836 321666 341203 36077 492023 495910 506458 530196 607654 673944 73753 780690 811386 813891 833536 853767 866648 868614 871719 900420 919207 972727 99776 ; do
echo ./aggregate_somatic_vcfs.bash $sample \>\> ${sample}.aggregate_somatic_vcfs.log 2\>\&1
done | parallel -j 40 --no-notice --joblog parallel.aggregate.log &





What makes a mutation?

for sample in 983899 268325 439338 63185 634370 ; do
zcat ${sample}.somatic/${sample}.strelka.filtered.allele_ratios.csv.gz | tail -n +2 | awk -F"\t" '{ if( $3 == 0 )print 0; else print 1}' | sort | uniq -c
done

for sample in 983899 268325 439338 63185 634370 ; do
zcat ${sample}.somatic/${sample}.strelka.filtered.allele_ratios.csv.gz | tail -n +2 | awk -F"\t" '{ if( $5 == 0 && $6 == 0 )print 0; else print 1}' | sort | uniq -c
done

for sample in 983899 268325 439338 63185 634370 ; do
zcat ${sample}.somatic/${sample}.strelka.filtered.allele_ratios.csv.gz | tail -n +2 | awk -F"\t" '{ if( $3 < 0.5 )print 0; else print 1}' | sort | uniq -c
done


for sample in 983899 268325 439338 63185 634370 ; do
cd ${sample}.somatic
../tumor-normal-isec-counts.bash > tumor-normal-isec-counts.csv &
cd ..
done



20190528

Sanger has released version 3 of its signatures.
deconstructSigs does not include this reference matrix yet so let's see if we can make it.
https://www.synapse.org/#!Synapse:syn12025148
Maybe even try to reconstruct version 2 for that warm fuzzy feeling. (can't find the raw v2)

cd ~/github/raerose01/deconstructSigs/data/
R
load("signatures.cosmic.rda")
write.csv(signatures.cosmic,file="signatures.cosmic.csv")
quit()


wc -l signatures.cosmic.csv
31 signatures.cosmic.csv


awk 'BEGIN{FS=OFS=","}{ print NF }' signatures.cosmic.csv | uniq -c
     31 97


awk 'BEGIN{FS=OFS=","}( NR < 5 ){ print $1,$2,$3,$4,$5 }' signatures.cosmic.csv 
"","A[C>A]A","A[C>A]C","A[C>A]G","A[C>A]T"
"Signature.1",0.011098326166,0.009149340734,0.001490070468,0.006233885236
"Signature.2",0.000682708227,0.000619107232,9.9278956e-05,0.000323891363
"Signature.3",0.022172306775,0.017871675353,0.002138339617,0.01626514559


The new file is rotated and has a type and subtype, so I got work to do.

Merge Type and Subtype FIRST!

awk 'BEGIN{FS=OFS=","}(NR==1){printf("\"sig\"")}(NR>1){split($2,a,"");printf("\"%s[%s]%s\"",a[1],$1,a[3])}{for(i=3;i<=NF;i++)printf(",%s",$i);printf("\n")}' sigProfiler_SBS_signatures_2019_05_22.csv > sigProfiler_SBS_signatures_2019_05_22.merged.csv

THEN transpose.

datamash transpose -t , < sigProfiler_SBS_signatures_2019_05_22.merged.csv > sigProfiler_SBS_signatures_2019_05_22.merged.tp.csv

For some reason, this added control-M's after field. Can't figure out why.
sed -i -e 's/\r//g' sigProfiler_SBS_signatures_2019_05_22.merged.tp.csv

cp sigProfiler_SBS_signatures_2019_05_22.merged.tp.csv ~/github/raerose01/deconstructSigs/data/


R
signatures.v3 <- read.csv(file="sigProfiler_SBS_signatures_2019_05_22.merged.tp.csv",check.names=FALSE,row.names='sig')
save(signatures.v3,file="signatures.v3.rda")


cp signatures.v3.rda ~/github/unreno/genomics/dev/data_sets/CCLS/20190417-vcf-recreation-and-analysis/bam/



--------------------------------------------------

20190617

Gonna do differing AD groups so more clearly name those already done (and in scripts)

rename 's/Bias.AD./Bias.AD.0.04-/' 1*somatic/*Bias.AD.*
rename 's/Bias.AD./Bias.AD.0.04-/' 2*somatic/*Bias.AD.*
rename 's/Bias.AD./Bias.AD.0.04-/' 3*somatic/*Bias.AD.*
rename 's/Bias.AD./Bias.AD.0.04-/' 4*somatic/*Bias.AD.*
rename 's/Bias.AD./Bias.AD.0.04-/' 5*somatic/*Bias.AD.*
rename 's/Bias.AD./Bias.AD.0.04-/' 6[0-2]*somatic/*Bias.AD.*
rename 's/Bias.AD./Bias.AD.0.04-/' 6[3-6]*somatic/*Bias.AD.*
rename 's/Bias.AD./Bias.AD.0.04-/' 6[7-9]*somatic/*Bias.AD.*
rename 's/Bias.AD./Bias.AD.0.04-/' 7*somatic/*Bias.AD.*
rename 's/Bias.AD./Bias.AD.0.04-/' 8*somatic/*Bias.AD.*
rename 's/Bias.AD./Bias.AD.0.04-/' 9*somatic/*Bias.AD.*

The above is now moot as I need to rerun with a modified filter.

find *.somatic -name \*GNOMAD_AF.Bias.AD.\* -exec chmod -R a+w {} \;
find *.somatic -name \*GNOMAD_AF.Bias.AD.\* -exec rm -rf {} \;

for sample in 983899 268325 439338 63185 634370 ; do
for chr in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X ; do
echo ./create_somatic_vcfs.bash $sample $chr \>\> ${sample}.${chr}.create_somatic_vcfs.log 2\>\&1
done ; done | parallel -j 40 --no-notice --joblog parallel.create.log &

for sample in 983899 268325 439338 63185 634370 ; do
echo ./aggregate_somatic_vcfs.bash $sample \>\> ${sample}.aggregate_somatic_vcfs.log 2\>\&1
done | parallel -j 40 --no-notice --joblog parallel.aggregate.log &


nohup ./mutations.bash > mutations.out 2> mutations.err &


Use -execdir instead of -exec (for some reason) and + instead of \; because somehow it groups (like xargs) and runs faster?
find . -name \*\.AF0.2-\* -execdir rename 's/\.AF0.2-/.AF0.20-/' {} +
find . -name \*DP200\* -execdir rename 's/DP200/DP10-200/' {} +



find . -name \*annotate\* -execdir rename 's/annotate/gnomad/' {} +
find . -name \*GNOMAD_AF\* -execdir rename 's/GNOMAD_AF/gAF0-0.001/' {} +



for sample in 983899 268325 439338 63185 634370 120207 122997 186069 201771 209605 266836 321666 341203 36077 492023 495910 506458 530196 607654 673944 73753 780690 811386 813891 833536 853767 866648 868614 871719 900420 919207 972727 99776 ; do
for chr in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X ; do
echo ./create_somatic_vcfs.bash $sample $chr \>\> ${sample}.${chr}.create_somatic_vcfs.log 2\>\&1
done ; done | parallel -j 40 --no-notice --joblog parallel.create.log &


for sample in 983899 268325 439338 63185 634370 120207 122997 186069 201771 209605 266836 321666 341203 36077 492023 495910 506458 530196 607654 673944 73753 780690 811386 813891 833536 853767 866648 868614 871719 900420 919207 972727 99776 ; do
echo ./aggregate_somatic_vcfs.bash $sample \>\> ${sample}.aggregate_somatic_vcfs.log 2\>\&1
done | parallel -j 40 --no-notice --joblog parallel.aggregate.log &


nohup ./mutations.bash > mutations.out 2> mutations.err &











20190808


Custom reorder several csv files ...

./reorder_mutations_csv.py mutations-20190716071807/v3/mutations-manual-0.001-0.10-0.40.csv
./reorder_mutations_csv.py mutations-20190716071807/v3/mutations-manual-0.0001-0.10-0.40.csv
./reorder_mutations_csv.py mutations-20190716071807/v3/mutations-manual-0.001-0.20-0.40.csv
./reorder_mutations_csv.py mutations-20190716071807/v3/mutations-manual-0.0001-0.20-0.40.csv


Manually extract APOBEC mutations TCA and TCT with C>G and C>T and combine ratio.

Added trinuc_muts_counts_ratios.py to aggregate_somatic_vcfs.bash

for sample in 983899 268325 439338 63185 634370 120207 122997 186069 201771 209605 266836 321666 341203 36077 492023 495910 506458 530196 607654 673944 73753 780690 811386 813891 833536 853767 866648 868614 871719 900420 919207 972727 99776 ; do
echo ./aggregate_somatic_vcfs.bash $sample \>\> ${sample}.aggregate_somatic_vcfs.log 2\>\&1
done | parallel -j 40 --no-notice --joblog parallel.aggregate.log &

./collect_apobec_ratios.bash > collected_apobec_ratios.csv






